{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "875d73c5-9aca-4759-a419-10f201f6f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from os import getcwd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import  defaultdict, Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf958bce-21d4-4456-86ab-326f722ca58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I loved this movie, it was fantastic!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What a waste of time, absolutely horrible.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An excellent film with great performances.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terrible movie, I hated it.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I enjoyed every minute of it.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The movie was boring and predictable.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant storytelling and amazing visuals!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not worth watching at all.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>One of the best movies I've seen.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Worst film ever. Don't recommend.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review sentiment\n",
       "0        I loved this movie, it was fantastic!  positive\n",
       "1   What a waste of time, absolutely horrible.  negative\n",
       "2   An excellent film with great performances.  positive\n",
       "3                  Terrible movie, I hated it.  negative\n",
       "4                I enjoyed every minute of it.  positive\n",
       "5        The movie was boring and predictable.  negative\n",
       "6  Brilliant storytelling and amazing visuals!  positive\n",
       "7                   Not worth watching at all.  negative\n",
       "8            One of the best movies I've seen.  positive\n",
       "9            Worst film ever. Don't recommend.  negative"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'review': [\n",
    "        \"I loved this movie, it was fantastic!\",\n",
    "        \"What a waste of time, absolutely horrible.\",\n",
    "        \"An excellent film with great performances.\",\n",
    "        \"Terrible movie, I hated it.\",\n",
    "        \"I enjoyed every minute of it.\",\n",
    "        \"The movie was boring and predictable.\",\n",
    "        \"Brilliant storytelling and amazing visuals!\",\n",
    "        \"Not worth watching at all.\",\n",
    "        \"One of the best movies I've seen.\",\n",
    "        \"Worst film ever. Don't recommend.\"\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        \"positive\", \"negative\", \"positive\", \"negative\", \"positive\",\n",
    "        \"negative\", \"positive\", \"negative\", \"positive\", \"negative\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# data = {\n",
    "#     'review': [\n",
    "#         \"I am happy because i am learning NLP\",\n",
    "#         \"I am happy not sad\",\n",
    "#         \"I am sad, I am not learning NLP\",\n",
    "#         \"I am sad, not happy\",\n",
    "#     ],\n",
    "#     'sentiment': [\n",
    "#         \"positive\", \"positive\", \"negative\", \"negative\"\n",
    "#     ]\n",
    "# }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01318ef2-39fa-4a69-a075-7ee19ff4f329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   [love, movi, fantast]\n",
       "1          [wast, time, absolut, horribl]\n",
       "2           [excel, film, great, perform]\n",
       "3                   [terribl, movi, hate]\n",
       "4                   [enjoy, everi, minut]\n",
       "5                   [movi, bore, predict]\n",
       "6     [brilliant, storytel, amaz, visual]\n",
       "7                          [worth, watch]\n",
       "8            [one, best, movi, ive, seen]\n",
       "9    [worst, film, ever, dont, recommend]\n",
       "Name: clean_review, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations = set(string.punctuation)\n",
    "stopwords = stop_words = {\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves',\n",
    "    'you', 'your', 'yours', 'yourself', 'yourselves',\n",
    "    'he', 'him', 'his', 'himself',\n",
    "    'she', 'her', 'hers', 'herself',\n",
    "    'it', 'its', 'itself',\n",
    "    'they', 'them', 'their', 'theirs', 'themselves',\n",
    "    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those',\n",
    "    'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "    'have', 'has', 'had', 'having',\n",
    "    'do', 'does', 'did', 'doing',\n",
    "    'a', 'an', 'the',\n",
    "    'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while',\n",
    "    'of', 'at', 'by', 'for', 'with', 'about', 'against',\n",
    "    'between', 'into', 'through', 'during', 'before', 'after',\n",
    "    'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under',\n",
    "    'again', 'further', 'then', 'once',\n",
    "    'here', 'there', 'when', 'where', 'why', 'how',\n",
    "    'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such',\n",
    "    'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very',\n",
    "    'can', 'will', 'just', 'don', 'should', 'now'\n",
    "}\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# preprocess data\n",
    "def preprocess_data(x):\n",
    "    x = x.lower()\n",
    "    x = \"\".join(char for char in x if char not in punctuations)\n",
    "    words = word_tokenize(x)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    stemmed = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "df[\"clean_review\"] = df[\"review\"].apply(preprocess_data)\n",
    "df[\"clean_review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b813096-74e5-4c95-8f71-d56cb89657b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train:  (7,)\n",
      "Shape X_test:  (3,)\n",
      "Shape y_train:  (7,)\n",
      "Shape y_test:  (3,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"clean_review\"], df[\"sentiment\"], test_size = 0.3, random_state = 42)\n",
    "\n",
    "print(\"Shape X_train: \", X_train.shape)\n",
    "print(\"Shape X_test: \", X_test.shape)\n",
    "print(\"Shape y_train: \", y_train.shape)\n",
    "print(\"Shape y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1000f632-36f1-45c0-8fa1-491fa6ece18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                   [love, movi, fantast]\n",
       " 7                          [worth, watch]\n",
       " 2           [excel, film, great, perform]\n",
       " 9    [worst, film, ever, dont, recommend]\n",
       " 4                   [enjoy, everi, minut]\n",
       " 3                   [terribl, movi, hate]\n",
       " 6     [brilliant, storytel, amaz, visual]\n",
       " Name: clean_review, dtype: object,\n",
       " 0    positive\n",
       " 7    negative\n",
       " 2    positive\n",
       " 9    negative\n",
       " 4    positive\n",
       " 3    negative\n",
       " 6    positive\n",
       " Name: sentiment, dtype: object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8355927d-0382-436f-aa37-1e0a0ef64833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word frequnecy: defaultdict(<function build_word_freq.<locals>.<lambda> at 0x0000022786DFE5C0>, {'love': {'positive': 1, 'negative': 0}, 'movi': {'positive': 1, 'negative': 1}, 'fantast': {'positive': 1, 'negative': 0}, 'worth': {'positive': 0, 'negative': 1}, 'watch': {'positive': 0, 'negative': 1}, 'excel': {'positive': 1, 'negative': 0}, 'film': {'positive': 1, 'negative': 1}, 'great': {'positive': 1, 'negative': 0}, 'perform': {'positive': 1, 'negative': 0}, 'worst': {'positive': 0, 'negative': 1}, 'ever': {'positive': 0, 'negative': 1}, 'dont': {'positive': 0, 'negative': 1}, 'recommend': {'positive': 0, 'negative': 1}, 'enjoy': {'positive': 1, 'negative': 0}, 'everi': {'positive': 1, 'negative': 0}, 'minut': {'positive': 1, 'negative': 0}, 'terribl': {'positive': 0, 'negative': 1}, 'hate': {'positive': 0, 'negative': 1}, 'brilliant': {'positive': 1, 'negative': 0}, 'storytel': {'positive': 1, 'negative': 0}, 'amaz': {'positive': 1, 'negative': 0}, 'visual': {'positive': 1, 'negative': 0}})\n",
      " Total positive class occurences: 14\n",
      " Total negative class occurences: 10\n"
     ]
    }
   ],
   "source": [
    "# build word frequency\n",
    "def build_word_freq(x, y):\n",
    "    word_freq = defaultdict(lambda: {'positive': 0, \"negative\": 0})\n",
    "    for words, review in zip(x, y):\n",
    "        for word in words:\n",
    "            word_freq[word][review] += 1\n",
    "\n",
    "    n_pos = 0\n",
    "    n_neg = 0\n",
    "    for word in word_freq:\n",
    "        n_pos += word_freq[word][\"positive\"]\n",
    "        n_neg += word_freq[word][\"negative\"]\n",
    "        \n",
    "    return word_freq, n_pos, n_neg\n",
    "\n",
    "word_freq, n_pos, n_neg = build_word_freq(X_train, y_train)\n",
    "\n",
    "print(f\"Word frequnecy: {word_freq}\\n Total positive class occurences: {n_pos}\\n Total negative class occurences: {n_neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8266147e-2bea-44df-a36e-37f13a8939b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.build_word_freq.<locals>.<lambda>()>,\n",
       "            {'love': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'movi': {'positive': 1,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.11778303565638351},\n",
       "             'fantast': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'worth': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'watch': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'excel': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'film': {'positive': 1,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.11778303565638351},\n",
       "             'great': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'perform': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'worst': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'ever': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'dont': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'recommend': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'enjoy': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'everi': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'minut': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'terribl': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'hate': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'brilliant': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'storytel': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'amaz': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'visual': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618}})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build conditional liklihood\n",
    "def build_prob(word_freq, n_pos, n_neg):\n",
    "    vocab_size = len(word_freq)\n",
    "    \n",
    "    for word, freqs in word_freq.items():\n",
    "        word_freq[word][\"p_pos\"] = (freqs[\"positive\"] + 1) / (n_pos + vocab_size)\n",
    "        word_freq[word][\"p_neg\"] = (freqs[\"negative\"] + 1) / (n_neg + vocab_size)\n",
    "        \n",
    "    return word_freq\n",
    "\n",
    "word_freq_prob = build_prob(word_freq, n_pos, n_neg)\n",
    "word_freq_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a472ebd2-d7db-4343-991f-bebc5d71c1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.build_word_freq.<locals>.<lambda>()>,\n",
       "            {'love': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'movi': {'positive': 1,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.11778303565638351},\n",
       "             'fantast': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'worth': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'watch': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'excel': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'film': {'positive': 1,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.11778303565638351},\n",
       "             'great': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'perform': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'worst': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'ever': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'dont': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'recommend': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'enjoy': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'everi': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'minut': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'terribl': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'hate': {'positive': 0,\n",
       "              'negative': 1,\n",
       "              'p_pos': 0.027777777777777776,\n",
       "              'p_neg': 0.0625,\n",
       "              'lambda': -0.8109302162163288},\n",
       "             'brilliant': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'storytel': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'amaz': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618},\n",
       "             'visual': {'positive': 1,\n",
       "              'negative': 0,\n",
       "              'p_pos': 0.05555555555555555,\n",
       "              'p_neg': 0.03125,\n",
       "              'lambda': 0.5753641449035618}})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get log liklihood of each word\n",
    "def get_log_liklihood(word_freq_prob):\n",
    "    for word in word_freq_prob:\n",
    "        word_freq_prob[word][\"lambda\"] = math.log(word_freq_prob[word][\"p_pos\"] / word_freq_prob[word][\"p_neg\"])\n",
    "\n",
    "    return word_freq_prob\n",
    "\n",
    "word_freq_prob = get_log_liklihood(word_freq_prob)\n",
    "word_freq_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3203fb6f-b1f3-4efa-8af4-bf0b0fafd77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_positive': 0.5714285714285714, 'p_negative': 0.42857142857142855}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get log prior of positive and negative classes\n",
    "def get_log_prior(y):\n",
    "    label_counts = Counter(y)\n",
    "    n_total = len(y)\n",
    "    \n",
    "    log_priors = {}\n",
    "    for label in label_counts:\n",
    "        log_priors[f\"p_{label}\"] = label_counts[label] / n_total\n",
    "\n",
    "    return log_priors\n",
    "\n",
    "log_priors = get_log_prior(y_train)\n",
    "log_priors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf6782-9894-46ef-aee7-1f57c426bb3a",
   "metadata": {},
   "source": [
    "### Inference on test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "acb56c2c-08b3-4d1b-8c29-18c4d09eb639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_message(text, word_freq_prob, log_priors):\n",
    "    stemmed_words = preprocess_data(text)\n",
    "    log_liklihood = 0\n",
    "    \n",
    "    for word in stemmed_words:\n",
    "        if word not in word_freq_prob.keys():\n",
    "            continue\n",
    "        log_liklihood += word_freq_prob[word][\"lambda\"]\n",
    "\n",
    "    score = math.log(log_priors[\"p_positive\"] / log_priors[\"p_negative\"]) + log_liklihood\n",
    "\n",
    "    if score > 0:\n",
    "        return f\"Positive Sentiment ==> with Score = {score}\"\n",
    "    elif score < 0:\n",
    "        return f\"Negative Sentiment ==> with Score = {score}\"\n",
    "    else:\n",
    "        return f\"Neutral Sentiment ==> with Score = {score}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d908acd5-24c0-4504-9f60-b4a34535862f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive Sentiment ==> with Score = 0.16989903679539733'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_message(\"One of the best movies I've seen.\", word_freq_prob, log_priors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
